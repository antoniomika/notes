{"componentChunkName":"component---src-gatsby-theme-code-notes-templates-note-js","path":"/zfs-nas/","result":{"data":{"mdx":{"body":"var _excluded = [\"components\"];\nfunction _extends() { _extends = Object.assign ? Object.assign.bind() : function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n/* @jsxRuntime classic */\n/* @jsx mdx */\n\nvar _frontmatter = {\n  \"title\": \"Roll you own ZFS NAS\",\n  \"tags\": [\"blog\"],\n  \"emoji\": \"\",\n  \"link\": \"\",\n  \"date\": \"2024-03-13\"\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n    props = _objectWithoutProperties(_ref, _excluded);\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"h2\", {\n    \"id\": \"background\"\n  }, \"Background\"), mdx(\"p\", null, \"Recently I've noticed an uptick in the engagement found within the self-hosting community,\\nso I've decided to start a series of posts that look into why and how I handle self-hosting.\\nToday's post will focus on data storage and will look into some of the options available when\\nit comes to data backups.\"), mdx(\"p\", null, \"Data storage is hard. Data backup is even harder. Therefore, I spent some time recently\\nto re-evaluate my backup strategy. Prior to deciding to roll my own backup solution, I would generally\\nbackup files to Google Drive as my main \\\"backup\\\" mechanism. This was quite a shameful setup but gave\\nme a good amount of storage with easy access to all of my data. I used the Enterprise Workspace plan\\nwhich gave me access to as much storage as I needed, but Google soon changed their offering. I was using\\n~9TB of storage at that time, so once they removed the \\\"as much as you need\\\" provision, I had to use 2 users\\nworth of pooled storage. This amounts to ~$40/mo, which is still not terrible for data storage that is\\nfairly reliable.\"), mdx(\"h2\", {\n    \"id\": \"its-as-easy-as-3-2-1\"\n  }, \"It's as easy as 3-2-1\"), mdx(\"p\", null, \"When architecting my new backup strategy, I decided it was time for an upgrade. Generally, the 3-2-1\\ndata backup method is recommended. The idea with this strategy is you maintain \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"3\"), \" different copies of\\nyour data, with 2 copies stored in two different locations/media, and 1 copy stored at an offsite location.\\nThis setup is pretty easy to achieve and provides pretty good fault-tolerance and disaster recovery.\\nIt also ensures that your data is protected when the unthinkable happens.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"|--------|    |---------|    |---------|\\n|   3    | -> | 2 Media | -> |    1    |\\n| Copies |    |  Types  |    | Offsite |\\n|--------|    |---------|    |---------|\\n\")), mdx(\"p\", null, \"Achieving this backup strategy isn't particularly difficult to do. A simple setup with this scheme could\\nbe done with the following:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Primary data source (a laptop)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A backup of the primary data source (a usb or external hard drive)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A backup of the primary data source (a cloud backup)\")), mdx(\"p\", null, \"With a setup like this, we end up with 3 copies of our data. We have at least 2 different types of media\\n(external hard drive and cloud storage), and one copy offsite (in the cloud). Therefore, we should have\\nfairly decent data redundancy.\"), mdx(\"h2\", {\n    \"id\": \"my-strategy\"\n  }, \"My strategy\"), mdx(\"p\", null, \"Based on the above and for my own purposes, I decided a viable backup process would involve the following:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"Primary data source (laptops, desktops, phones, etc)\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A backup of the primary data to the NAS at home\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A backup of the NAS at home to a similar NAS offsite\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A backup of the NAS to the cloud\")), mdx(\"p\", null, \"This scheme gives me a decent amount of flexibility and options for backing up my data, as well as generally\\nfollows the 3-2-1 rule I described above. The main benefit of using this method is that each device I backup only\\nneeds to keep track of a single backup target. That backup target then can be easily backed up to a secondary target\\nwithout the primary device needing to have any intervention. In the event the backup target is destroyed, it can be\\nreplaced by the secondary target, and the secondary target replaced by a new device with all of the data replicated\\nto it. This ensures that in the event a device is lost, data is still well protected and devices can be replaced easily\\nwith minimal downtime since we can promote devices to take each other's place as needed.\"), mdx(\"h2\", {\n    \"id\": \"technologies\"\n  }, \"Technologies\"), mdx(\"p\", null, \"Primary data sources would be backed up using the following:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.borgbackup.org/\"\n  }, \"Borg\"), \" (via \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://torsion.org/borgmatic/\"\n  }, \"Borgmatic\"), \" or \", mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://vorta.borgbase.com/\"\n  }, \"Vorta\"), \") for linux/macos hosts using\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://rsync.samba.org/\"\n  }, \"rsync\"), \" for random hosts/data that don't need dedupe and other Borg niceties\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://www.samba.org/\"\n  }, \"samba\"), \" for Windows\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://netatalk.io/\"\n  }, \"netatalk\"), \" for macOS/Time Machine\")), mdx(\"p\", null, \"The backup targets would be machines running Ubuntu Server 22.04 LTS. All backup data would be stored in ZFS,\\nwhich would ultimately make our desired scheme trivial to implement. They would have the following configuration:\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"32gb of ram\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"8 core cpu, 3.5ghz base clock\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"4 18tb HDDs using ZFS and in a single zpool\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, \"A small HDD for OS install\")), mdx(\"p\", null, \"For the base OS, the default installation parameters were chosen. Regarding the actual backup storage devices (the 18tb HDDs),\\na zpool was created that consisted of two mirrored vdevs, with each mirror containing 2 disks. This strategy provides decent\\nredundancy in the case that a disk fails (we can lose up to one disk in each vdev), while also allowing us to grow the pool in\\nthe future. If the pool is ever running low on data, we can easily add another vdev of 2 disks to increase the capacity. This\\nmethod does result in our storage pool having capacity of half the total disk space we have available (18tb * 2 vdevs = 36tb).\"), mdx(\"p\", null, \"Over using zraid, this option gives us fantastic performance, good scalability, and ease of management.\"), mdx(\"p\", null, \"The choice of ZFS simplifies our NAS backups, as we can utilize the ability of ZFS to send and receive snapshots to send backups\\nof our data. This is a huge benefit as it simplifies the backup process tremendously. Our systems are large enough that the overhead\\nof running ZFS itself should be neglible, and we can reap huge benefits in our ability to easily replicate our data. Snapshots don't\\ncost us anything to use (a huge benefit due to the fact that ZFS is CoW), so we can feel safe knowing that we can use them.\"), mdx(\"h2\", {\n    \"id\": \"backup-setup\"\n  }, \"Backup Setup\"), mdx(\"h3\", {\n    \"id\": \"zfs-setup\"\n  }, \"ZFS Setup\"), mdx(\"p\", null, \"The setup process for each NAS was pretty much the same and can be summarized by the following:\"), mdx(\"ol\", null, mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Install ZFS on Linux and setup the zpool named \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"backup\"), \":\"), mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"# Install ZoL\\napt-get update && apt-get install zfsutils-linux -y\\n\\n# Get the list of devices by their ids to ensure\\n# they are found correctly when the pool is imported:\\nls /dev/disk/by-id/*\\n\\n# Create the mirrored pool with the first vdev\\nzpool create -o ashift={ashift} backup mirror \\\\\\n  /dev/disk/by-id/{device_id_here} \\\\\\n  /dev/disk/by-id/{device_id_here}\\n\\n# Add another vdev to the pool (can be done as many times as we want, expanding the pool)\\nzpool add -o ashift={ashift} backup mirror \\\\\\n  /dev/disk/by-id/{device_id_here} \\\\\\n  /dev/disk/by-id/{device_id_here}\\n\\n# Enable compression for the pool (if desired)\\nzfs set compression=on backup\\n\\n# Disable mounting for the pool (if desired)\\nzfs set canmount=off backup\\n\")), mdx(\"blockquote\", {\n    parentName: \"li\"\n  }, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, mdx(\"strong\", {\n    parentName: \"p\"\n  }, mdx(\"em\", {\n    parentName: \"strong\"\n  }, \"NOTE:\")), \" I decided to use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"compression=on\"), \", but you can tune this to your own preferences.\\nI also decided not to encrypt the entire zpool, so I could control this per-dataset (and therefore),\\nhave different encryption keys per dataset.\"))), mdx(\"li\", {\n    parentName: \"ol\"\n  }, mdx(\"p\", {\n    parentName: \"li\"\n  }, \"Setup the different datasets you want:\"), mdx(\"pre\", {\n    parentName: \"li\"\n  }, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"# Create an encrypted dataset for borg\\nzfs create -o encryption=aes-256-gcm \\\\\\n  -o keylocation=prompt \\\\\\n  -o keyformat=passphrase \\\\\\n  backup/borg\\n\\n# Create an encrypted dataset for misc\\nzfs create -o encryption=aes-256-gcm \\\\\\n  -o keylocation=prompt \\\\\\n  -o keyformat=passphrase \\\\\\n  backup/misc\\n\\n# Create an encrypted dataset for macos\\nzfs create -o encryption=aes-256-gcm \\\\\\n  -o keylocation=prompt \\\\\\n  -o keyformat=passphrase \\\\\\n  backup/macos\\n\\n# Create an encrypted dataset for windows\\nzfs create -o encryption=aes-256-gcm \\\\\\n  -o keylocation=prompt \\\\\\n  -o keyformat=passphrase \\\\\\n  backup/windows\\n\")))), mdx(\"h3\", {\n    \"id\": \"ssh-setup-borg-and-rsync\"\n  }, \"SSH Setup (borg and rsync)\"), mdx(\"h3\", {\n    \"id\": \"samba-setup\"\n  }, \"Samba Setup\"), mdx(\"h3\", {\n    \"id\": \"netatalk-setup\"\n  }, \"Netatalk Setup\"), mdx(\"h2\", {\n    \"id\": \"replication-setup\"\n  }, \"Replication Setup\"), mdx(\"h3\", {\n    \"id\": \"zfs-snapshots\"\n  }, \"ZFS Snapshots\"), mdx(\"h3\", {\n    \"id\": \"automated-send-and-receive\"\n  }, \"Automated send and receive\"));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Roll you own ZFS NAS","tags":["blog"],"emoji":"","link":"","date":"2024-03-13"},"fields":{"dateModified":"16th Mar 2024","slug":"/zfs-nas/"},"tableOfContents":{"items":[{"url":"#background","title":"Background"},{"url":"#its-as-easy-as-3-2-1","title":"It's as easy as 3-2-1"},{"url":"#my-strategy","title":"My strategy"},{"url":"#technologies","title":"Technologies"},{"url":"#backup-setup","title":"Backup Setup","items":[{"url":"#zfs-setup","title":"ZFS Setup"},{"url":"#ssh-setup-borg-and-rsync","title":"SSH Setup (borg and rsync)"},{"url":"#samba-setup","title":"Samba Setup"},{"url":"#netatalk-setup","title":"Netatalk Setup"}]},{"url":"#replication-setup","title":"Replication Setup","items":[{"url":"#zfs-snapshots","title":"ZFS Snapshots"},{"url":"#automated-send-and-receive","title":"Automated send and receive"}]}]},"parent":{"__typename":"File","name":"zfs-nas","fileName":"zfs-nas.md"}}},"pageContext":{"id":"d2dbe321-8325-581c-89d9-5a5b78b1c0d9","previous":{"id":"938475a9-8524-575e-a67e-8b4afc08093b","frontmatter":{"title":"Shell Sharing using TCP Sockets","tags":["blog"]},"fields":{"slug":"/shell-sharing/"}},"next":{"id":"e77a3740-52b8-50c9-998d-9fba78f5f155","frontmatter":{"title":"Hello World!","tags":["blog"]},"fields":{"slug":"/hello-world/"}},"hasUntagged":false,"basePath":"/"}},"staticQueryHashes":["1322576299","1437003973","467212769","467212769"]}